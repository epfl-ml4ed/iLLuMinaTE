{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd7e0723",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nbformat --quiet\n",
    "!pip install --upgrade langchain --quiet\n",
    "!pip install openai --quiet\n",
    "!pip install python-dotenv --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "943eb74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from MC_LIME import *\n",
    "import pandas as pd\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "import re\n",
    "from chat_open_ai import chat_openai_model\n",
    "\n",
    "# External functions\n",
    "from functions_pipeline import *\n",
    "from prompt_templates import TEMPLATES\n",
    "\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5c244c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e057383a",
   "metadata": {},
   "source": [
    "### Metavariables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a634f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_WEEKS=5\n",
    "\n",
    "LIME_bool=True\n",
    "MC_LIME_bool=False\n",
    "CEM_bool=False\n",
    "average_class=False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e083c4",
   "metadata": {},
   "source": [
    "## Import data & model\n",
    "- Which student data to pick?\n",
    "- Feature scores of the student\n",
    "- LIME results OR MC-LIME results (depending on the strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "504cca24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-15 12:10:46.728698: W tensorflow/core/common_runtime/graph_constructor.cc:834] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2024-07-15 12:10:46.949485: W tensorflow/core/common_runtime/graph_constructor.cc:834] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2024-07-15 12:10:47.266261: W tensorflow/core/common_runtime/graph_constructor.cc:834] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2024-07-15 12:10:47.271366: W tensorflow/core/common_runtime/graph_constructor.cc:834] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2024-07-15 12:10:47.467576: W tensorflow/core/common_runtime/graph_constructor.cc:834] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2024-07-15 12:10:47.826055: W tensorflow/core/common_runtime/graph_constructor.cc:834] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2024-07-15 12:10:47.888818: W tensorflow/core/common_runtime/graph_constructor.cc:834] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2024-07-15 12:10:47.892833: W tensorflow/core/common_runtime/graph_constructor.cc:834] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 140)\n"
     ]
    }
   ],
   "source": [
    "# CHANGE HERE THE FEATURE SET\n",
    "feature_set=f\"features/dsp_001_features_5_weeks.csv\" \n",
    "features = pd.read_csv(feature_set)\n",
    "\n",
    "# GET PREDICTION MODEL\n",
    "model_path = 'models/'\n",
    "course='dsp_001'\n",
    "loaded_model=get_model(model_path, course, NUM_WEEKS)\n",
    "\n",
    "mapping=pd.read_csv(\"data/user_id_mapping-dsp_001.csv\", index_col=0)\n",
    "students_ids=pd.read_csv(\"data/representative_samples.csv\")[\"user_id\"]\n",
    "indices = mapping.index[mapping['user_id'].isin(students_ids)].tolist()\n",
    "\n",
    "# Retrieve data for student idx\n",
    "lime_path=f\"OLD_uniform_eq_results_ori_{str(NUM_WEEKS)}_weeks/LIME/{course}/dataframes/\"\n",
    "cem_path=f\"OLD_uniform_eq_results_ori_5_weeks/CEM/{course}/\"\n",
    "mapping={\"Pass\" : 0, \"Fail\" : 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3817eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change here the student index to test\n",
    "idx=6478"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12af577c",
   "metadata": {},
   "source": [
    "# Create list of prompts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "745150ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'OLD_uniform_eq_results_ori_5_weeks/CEM/dsp_001/6478.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m format_instructions \u001b[38;5;241m=\u001b[39m TEMPLATES[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_instructions\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      7\u001b[0m course_description \u001b[38;5;241m=\u001b[39m TEMPLATES[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcourse_description_dsp_001\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m----> 8\u001b[0m data_string \u001b[38;5;241m=\u001b[39m get_data(course, loaded_model, idx, features, lime_path, cem_path, MC_LIME_bool, LIME_bool, CEM_bool, average_class)\n\u001b[1;32m      9\u001b[0m conversation_template \u001b[38;5;241m=\u001b[39m TEMPLATES[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconversation_template\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Desktop/EPFL/XAI Semester Project/llm-xai/functions_pipeline.py:236\u001b[0m, in \u001b[0;36mget_data\u001b[0;34m(course, loaded_model, idx, instances, features, lime_path, cem_path, MC_LIME_bool, LIME_bool, CEM_bool, average_class)\u001b[0m\n\u001b[1;32m    234\u001b[0m inverse_mapping \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m0\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpass\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfail\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m    235\u001b[0m data_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 236\u001b[0m important_features, student_features, step_sizes, y_pred, confidence \u001b[38;5;241m=\u001b[39m get_lime_results(loaded_model, features, lime_path, idx, mapping)\n\u001b[1;32m    238\u001b[0m average_values \u001b[38;5;241m=\u001b[39m features[important_features\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mvalues]\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m    240\u001b[0m \u001b[38;5;66;03m# Create dict for important features values\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/EPFL/XAI Semester Project/llm-xai/functions_pipeline.py:160\u001b[0m, in \u001b[0;36mget_lime_results\u001b[0;34m(loaded_model, features, lime_path, idx, mapping)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_lime_results\u001b[39m(loaded_model, features, lime_path, idx, mapping):\n\u001b[1;32m    157\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;124;03m    Get the LIME results for a specific student and process them.\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 160\u001b[0m     results\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mread_csv(lime_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(idx) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    161\u001b[0m     results\u001b[38;5;241m=\u001b[39minit_processing(results)\n\u001b[1;32m    163\u001b[0m     top_columns\u001b[38;5;241m=\u001b[39mresults\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mvalues\n",
      "File \u001b[0;32m~/anaconda3/envs/xai/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/anaconda3/envs/xai/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/envs/xai/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m~/anaconda3/envs/xai/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1881\u001b[0m     f,\n\u001b[1;32m   1882\u001b[0m     mode,\n\u001b[1;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1889\u001b[0m )\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/envs/xai/lib/python3.11/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'OLD_uniform_eq_results_ori_5_weeks/CEM/dsp_001/6478.csv'"
     ]
    }
   ],
   "source": [
    "template=TEMPLATES[\"template\"]\n",
    "goal_definition = TEMPLATES[\"goal_definition\"]\n",
    "features_description = get_features_description(features)\n",
    "model_description = TEMPLATES[\"model_description\"]\n",
    "post_hoc_description = define_post_hoc_description(LIME_bool, MC_LIME_bool, CEM_bool)\n",
    "format_instructions = TEMPLATES[\"format_instructions\"]\n",
    "course_description = TEMPLATES[\"course_description_dsp_001\"]\n",
    "data_string = get_data(course, loaded_model, idx, features, lime_path, cem_path, MC_LIME_bool, LIME_bool, CEM_bool, average_class)\n",
    "conversation_template = TEMPLATES[\"conversation_template\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2929807a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompt_class import prompt_class\n",
    "instructions_dataset=pd.read_csv(\"prompting_strategies.csv\")\n",
    "instructions_dataset=instructions_dataset[['name', 'Communication Prompt', 'LLM-Prompt2']]\n",
    "instructions_dataset = instructions_dataset[instructions_dataset['name'] != 'hesslow_contrastive']\n",
    "instructions_dataset = instructions_dataset.rename(columns={'Communication Prompt': 'instruction'})\n",
    "instructions_dataset\n",
    "\n",
    "prompt_object=prompt_class(template, instructions_dataset)\n",
    "\n",
    "context_string=prompt_object.context_partial_prompt( \n",
    "    data_string,\n",
    "    features_description, \n",
    "    goal_definition, \n",
    "    model_description, \n",
    "    post_hoc_description, \n",
    "    course_description,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7662bb",
   "metadata": {},
   "source": [
    "## Explanation presentation / evaluation\n",
    "In this step we give the LLM the last prompt to generate an explanation that is presented and communicated well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263ae755",
   "metadata": {},
   "outputs": [],
   "source": [
    "presentation_examples = \"\"\n",
    "\n",
    "# Here if you want to change the template\n",
    "presentation_template = \"\"\"\n",
    "Given this report, I want you to write a shorter version including: \n",
    "\n",
    "1. a brief description of the explanation findings \n",
    "2. Two recommended actions that the student can take.\n",
    "\n",
    "The student who is going to interact with you is the same student that the data is about. Imagine to be a professor giving feedback to a student.\n",
    "\n",
    "Follow the instructions underneath in the INSTRUCTIONS section. \n",
    "\n",
    "INSTRUCTIONS\n",
    "{presentation_intruction}\n",
    "\n",
    "Follow these rules:\n",
    "- do not use any feature names, feature scores, importance scores or how the ML model works. Describe the desired behaviour instead.\n",
    "- do not say the output of the model\n",
    "\n",
    "To communicate this intervention most effectively, use Grice’s maxims of conversation.\n",
    "\n",
    "- do not say things that you believe to be false\n",
    "- do not say things for which you do not have sufficient evidence.\n",
    "- do not add information that is not relevant\n",
    "- Only say what is relevant\n",
    "- be orderly\n",
    "\n",
    "Your goal is to explain to the student what they should do to improve their performance in the course in the best way possible.\n",
    "Follow the instructions above.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# \"\"\"\n",
    "# FORMAT\n",
    "\n",
    "# # Student Feedback\n",
    "# ### Explanation\n",
    "# [Your paragraphs here]\n",
    "\n",
    "# ### Recommendations\n",
    "# 1. **[Recommendation title]**: [Your recommendation here]\n",
    "# 2. **[Recommendation title]**: [Your recommendation here]\n",
    "\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e088be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>instruction</th>\n",
       "      <th>prompt</th>\n",
       "      <th>llm_prompt_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>relevance_selection</td>\n",
       "      <td>Use the social science theory “Relevance-Based...</td>\n",
       "      <td>[content=\"\\nYou are an AI assistant that analy...</td>\n",
       "      <td>[content='\\nGiven this report, I want you to w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abnormal_conditions</td>\n",
       "      <td>Use the social science theory “Abnormal Condit...</td>\n",
       "      <td>[content=\"\\nYou are an AI assistant that analy...</td>\n",
       "      <td>[content='\\nGiven this report, I want you to w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pearl_explanation</td>\n",
       "      <td>Use the social science theory “Pearl’s model o...</td>\n",
       "      <td>[content=\"\\nYou are an AI assistant that analy...</td>\n",
       "      <td>[content='\\nGiven this report, I want you to w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>necessity_robustness_selection</td>\n",
       "      <td>Use the social science theory “Necessity and R...</td>\n",
       "      <td>[content=\"\\nYou are an AI assistant that analy...</td>\n",
       "      <td>[content='\\nGiven this report, I want you to w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>contrastive_explanation</td>\n",
       "      <td>Use the social science theory “Contrastive Exp...</td>\n",
       "      <td>[content=\"\\nYou are an AI assistant that analy...</td>\n",
       "      <td>[content='\\nGiven this report, I want you to w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>base_contrastive_explanation</td>\n",
       "      <td>Use the social science theory “Contrastive Exp...</td>\n",
       "      <td>[content=\"\\nYou are an AI assistant that analy...</td>\n",
       "      <td>[content='\\nGiven this report, I want you to w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>statistical_relevance</td>\n",
       "      <td>Use the social science theory “Statistical Rel...</td>\n",
       "      <td>[content=\"\\nYou are an AI assistant that analy...</td>\n",
       "      <td>[content='\\nGiven this report, I want you to w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>chain_of_thought</td>\n",
       "      <td>Let’s think step-by-step</td>\n",
       "      <td>[content=\"\\nYou are an AI assistant that analy...</td>\n",
       "      <td>[content='\\nGiven this report, I want you to w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             name  \\\n",
       "0             relevance_selection   \n",
       "1             abnormal_conditions   \n",
       "2               pearl_explanation   \n",
       "3  necessity_robustness_selection   \n",
       "4         contrastive_explanation   \n",
       "6    base_contrastive_explanation   \n",
       "7           statistical_relevance   \n",
       "8                chain_of_thought   \n",
       "\n",
       "                                         instruction  \\\n",
       "0  Use the social science theory “Relevance-Based...   \n",
       "1  Use the social science theory “Abnormal Condit...   \n",
       "2  Use the social science theory “Pearl’s model o...   \n",
       "3  Use the social science theory “Necessity and R...   \n",
       "4  Use the social science theory “Contrastive Exp...   \n",
       "6  Use the social science theory “Contrastive Exp...   \n",
       "7  Use the social science theory “Statistical Rel...   \n",
       "8                           Let’s think step-by-step   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  [content=\"\\nYou are an AI assistant that analy...   \n",
       "1  [content=\"\\nYou are an AI assistant that analy...   \n",
       "2  [content=\"\\nYou are an AI assistant that analy...   \n",
       "3  [content=\"\\nYou are an AI assistant that analy...   \n",
       "4  [content=\"\\nYou are an AI assistant that analy...   \n",
       "6  [content=\"\\nYou are an AI assistant that analy...   \n",
       "7  [content=\"\\nYou are an AI assistant that analy...   \n",
       "8  [content=\"\\nYou are an AI assistant that analy...   \n",
       "\n",
       "                                        llm_prompt_2  \n",
       "0  [content='\\nGiven this report, I want you to w...  \n",
       "1  [content='\\nGiven this report, I want you to w...  \n",
       "2  [content='\\nGiven this report, I want you to w...  \n",
       "3  [content='\\nGiven this report, I want you to w...  \n",
       "4  [content='\\nGiven this report, I want you to w...  \n",
       "6  [content='\\nGiven this report, I want you to w...  \n",
       "7  [content='\\nGiven this report, I want you to w...  \n",
       "8  [content='\\nGiven this report, I want you to w...  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_object.add_explanation_template(presentation_template)\n",
    "prompt_object.create_prompts_list(instructions_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bac313e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "Given this report, I want you to write a shorter version including: \n",
       "\n",
       "1. a brief description of the explanation findings \n",
       "2. Two recommended actions that the student can take.\n",
       "\n",
       "The student who is going to interact with you is the same student that the data is about. Imagine to be a professor giving feedback to a student.\n",
       "\n",
       "Follow the instructions underneath in the INSTRUCTIONS section. \n",
       "\n",
       "INSTRUCTIONS\n",
       "Write a section called \"analysis\" with sentences that follow this structure:\n",
       "• Relevant Causes: Say to the student which causes you selected as relevant based on the question, context, and your background. Be explicit.\n",
       "• New Information: Say to the student which information you thought they knew already, such as \"Assuming that you know…\" and highlight aspects that haven't been previously communicated to the student. Be clear and honest.\n",
       "Finally:\n",
       "• Say to the student that you focused on the most relevant causes that provide new insights. Specify which causes you selected and why they are important.\n",
       "\n",
       "Follow these rules:\n",
       "- do not use any feature names, feature scores, importance scores or how the ML model works. Describe the desired behaviour instead.\n",
       "- do not say the output of the model\n",
       "\n",
       "To communicate this intervention most effectively, use Grice’s maxims of conversation.\n",
       "\n",
       "- do not say things that you believe to be false\n",
       "- do not say things for which you do not have sufficient evidence.\n",
       "- do not add information that is not relevant\n",
       "- Only say what is relevant\n",
       "- be orderly\n",
       "\n",
       "Your goal is to explain to the student what they should do to improve their performance in the course in the best way possible.\n",
       "Follow the instructions above.\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown, Latex\n",
    "import warnings\n",
    "\n",
    "presentation_prompt=prompt_object.prompting_strategies[\"llm_prompt_2\"][0]\n",
    "display(Markdown(presentation_prompt[0].content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c744febe",
   "metadata": {},
   "source": [
    "# Testing presentation prompt with the GPT API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7779f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE TO TEST CHANGES FOR THE PROMPT\n",
    "presentation_prompt=\"\"\"\n",
    "Given this report, I want you to write a shorter version including:\n",
    "\n",
    "a brief description of the explanation findings\n",
    "Two recommended actions that the student can take.\n",
    "The student who is going to interact with you is the same student that the data is about. Imagine to be a professor giving feedback to a student.\n",
    "\n",
    "Follow the instructions underneath in the INSTRUCTIONS section.\n",
    "\n",
    "INSTRUCTIONS Write a section called \"analysis\" with sentences that follow this structure: • Relevant Causes: Say to the student which causes you selected as relevant based on the question, context, and your background. Be explicit. • New Information: Say to the student which information you thought they knew already, such as \"Assuming that you know…\" and highlight aspects that haven't been previously communicated to the student. Be clear and honest. Finally: • Say to the student that you focused on the most relevant causes that provide new insights. Specify which causes you selected and why they are important.\n",
    "\n",
    "Follow these rules:\n",
    "\n",
    "do not use any feature names, feature scores, importance scores or how the ML model works. Describe the desired behaviour instead.\n",
    "do not say the output of the model\n",
    "To communicate this intervention most effectively, use Grice’s maxims of conversation.\n",
    "\n",
    "do not say things that you believe to be false\n",
    "do not say things for which you do not have sufficient evidence.\n",
    "do not add information that is not relevant\n",
    "Only say what is relevant\n",
    "be orderly\n",
    "Your goal is to explain to the student what they should do to improve their performance in the course in the best way possible. Follow the instructions above.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "37fbdee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPLANATION SELECTION PROMPT: DO THIS ONCE\n",
    "\n",
    "import os\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "# Change index for changing strategy\n",
    "test_prompt=prompt_object.prompting_strategies[\"prompt\"][0]\n",
    "\n",
    "# DEFINE LANGCHAIN MODEL\n",
    "llm_class=chat_openai_model(\"gpt-4o\", 0.5)\n",
    "conversation=llm_class.define_chat_model(conversation_template)\n",
    "\n",
    "# Here we call the model with the main prompt\n",
    "result1=conversation.predict(input=test_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d49d10b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do this to remove the previous presentation prompt and answer to test the next one\n",
    "conversation.memory.chat_memory.messages = conversation.memory.chat_memory.messages[:-2]\n",
    "assert len(conversation.memory.chat_memory.messages) == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "23d4b70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we call the model with the presentation prompt\n",
    "result2=conversation.predict(input=presentation_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "23bd1b97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Report on Student's Performance Prediction Using Necessity and Robustness Selection**\n",
       "\n",
       "**Introduction:**\n",
       "This report leverages the social science theory of \"Necessity and Robustness Selection\" to analyze the prediction of a student's performance in the Digital Signal Processing 1 course. The prediction model, based on a recurrent neural network, forecasts a 'pass' outcome with 75.713210% confidence. We utilize data from an explainable AI approach (LIME) and relevant student behavior data to derive insights.\n",
       "\n",
       "**Analysis:**\n",
       "\n",
       "1. **Defining Sets of Factors:**\n",
       "   The feature importances provided by LIME highlight several key factors influencing the student's predicted performance:\n",
       "   - **Competency Alignment:** Positive scores in Weeks 4 and 5 indicate that the student's ability to solve problems correctly in these weeks strongly supports a passing prediction. However, a high competency alignment in Week 3 negatively impacts the prediction.\n",
       "   - **Competency Strength:** Negative scores in Weeks 3, 4, and 5 suggest that the student's efficiency in solving problems (achieving maximum grades with few attempts) in these weeks adversely affects the passing prediction.\n",
       "   - **Total Clicks on Problems:** Negative scores in Weeks 4 and 5 indicate that an increase in problem-solving activity correlates negatively with the prediction, which might suggest inefficiency or struggle in these weeks.\n",
       "   - **Time Between Sessions Standard Deviation:** Positive scores in Weeks 4 and 5 suggest that more regular time intervals between study sessions contribute positively to the prediction.\n",
       "   - **Competency Anticipation:** Positive scores across multiple weeks indicate that the student's engagement with upcoming course content is a positive predictor of success.\n",
       "\n",
       "2. **Selection of Necessary Factors:**\n",
       "   The most necessary factors likely to cause the event (passing the course) include:\n",
       "   - **Competency Alignment in Week 5:** A score of 0.213 suggests this is a strong positive predictor, indicating effective problem-solving in the critical later stage of the course.\n",
       "   - **Competency Strength in Week 5:** Despite its negative impact (-0.175), this factor is crucial as it reflects on the student's approach to problem-solving.\n",
       "\n",
       "3. **Selection of Most Robust Explanation:**\n",
       "   The robustness of an explanation is determined by its stability under slightly varied conditions. The most robust factors in this analysis include:\n",
       "   - **Competency Alignment in Week 5:** This factor not only has a high positive score but is also supported by a zero feature value, suggesting that even minimal problem-solving effectiveness in the final weeks is critical for passing.\n",
       "   - **Time Between Sessions Standard Deviation in Week 5:** A positive impact coupled with a zero feature value indicates that maintaining consistent study intervals is crucial, regardless of their frequency or duration.\n",
       "\n",
       "**Conclusion:**\n",
       "The analysis concludes that the student's ability to effectively solve problems in the later weeks of the course (Week 5) and maintain regular study intervals are the most robust indicators of passing the course. Despite some negative impacts from competency strength, the overall prediction leans towards a pass, primarily driven by effective problem-solving and consistent study habits towards the end of the course. This insight could guide interventions aimed at enhancing student performance by focusing on consistent engagement and effective problem-solving strategies in critical weeks."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(result1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e628704a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Student Feedback\n",
       "### Explanation\n",
       "In analyzing your performance in the Digital Signal Processing 1 course, several factors have emerged as particularly influential. Your ability to solve problems effectively, especially in the later weeks of the course, plays a crucial role in your overall performance. Additionally, maintaining regular intervals between your study sessions contributes significantly to your learning success. These factors are essential as they directly relate to your problem-solving skills and study habits, which are critical for mastering the course content.\n",
       "\n",
       "Among these, the most necessary factor is your problem-solving effectiveness in the later stages of the course. This is a strong indicator of your grasp of the material and your readiness for assessments. The most robust explanation for your performance, which holds even under slightly varied conditions, is the consistency of your study intervals. This regularity in your study pattern helps ensure steady progress and better retention of the course material.\n",
       "\n",
       "### Recommendations\n",
       "1. **Enhance Problem-Solving Skills**: Focus on improving how effectively you solve problems, especially as you approach the end of the course. This might involve practicing with more complex problems or reviewing problem-solving strategies in study sessions.\n",
       "\n",
       "2. **Maintain Consistent Study Intervals**: Try to keep a regular schedule for your study sessions. This consistency helps in managing the course load effectively and reduces the cognitive burden of last-minute learning."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(result2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
